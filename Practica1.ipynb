{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9LIna0ePKm+0PCEy7Ri4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anamunoz01/AA_PRACTICA1_GRUPO_3/blob/main/Practica1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjS0Rz20khEw",
        "outputId": "33ec1e6a-2fea-46e5-be93-ec69f9b9bd6d"
      },
      "source": [
        "# 1._ IMPORTAMOS KERAS\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.keras.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n",
            "GPU Available: []\n",
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IvCzPOlkp0T"
      },
      "source": [
        "# Importamos las imágenes\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "#creamos vector con elementos\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opyZVSAIDJND"
      },
      "source": [
        "Estudiamos los **datos de entrenamiento**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbHjZJhUlZE9",
        "outputId": "57c36974-d459-465f-8df5-47296466380a"
      },
      "source": [
        "print(train_images.shape)\n",
        "\n",
        "train_images[50000]\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   2,   0,   1,   0,  16,  94,   0,   0,   2,   1,   1,   0,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,\n",
              "          1,   0,   0,   1,   0, 101, 196, 187,   8,   0,   0,   0,   1,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,\n",
              "          1,   0,   1,   0,   0, 161, 167, 166, 112,  11,   1,   0,   0,\n",
              "          6,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0,   3,   0, 121, 213, 187, 183, 180, 179, 155, 147, 129,\n",
              "        175,   8],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "          1,   2,   1,   0, 119, 198, 183, 185, 170, 185, 172, 170, 170,\n",
              "        146,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          2,   3,   0,   0, 175, 208, 176, 212, 180, 174, 166, 164, 164,\n",
              "        144,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          2,   0,   0,  73, 255, 192, 134, 175, 183, 192, 184, 189, 179,\n",
              "        193,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   1,\n",
              "          0,   0,  70, 192, 170, 134, 189, 192, 175, 157, 156, 171, 149,\n",
              "        180,   8],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   3,   1,   0,\n",
              "         35,  99, 181, 183, 126, 175, 197, 208, 203, 197, 188, 175, 158,\n",
              "        187,  14],\n",
              "       [  1,   1,   0,   0,   1,   1,   1,   1,   2,   2,   0,   0,  70,\n",
              "        188, 188, 116, 131, 180, 202, 190, 181, 188, 187, 175, 167, 156,\n",
              "        199,  34],\n",
              "       [  0,   0,   3,   3,   2,   0,   0,   0,   0,   0,   3,  69, 179,\n",
              "        106, 134, 151, 187, 183, 178, 171, 169, 187, 187, 183, 188, 167,\n",
              "        210,  53],\n",
              "       [  0,   0,   0,   0,   0,   0,   1,  11,  19,  57, 114, 130, 125,\n",
              "        129, 160, 174, 178, 184, 185, 196, 197, 198, 192, 188, 189, 166,\n",
              "        211,  52],\n",
              "       [  7,   0,  29,  87,  88, 105, 101,  99, 108, 110, 110, 137, 155,\n",
              "        166, 174, 179, 174, 176, 180, 181, 181, 180, 180, 184, 174, 169,\n",
              "        211,  66],\n",
              "       [  0,  19, 143, 119, 115, 116, 111, 114, 119, 116, 125, 139, 147,\n",
              "        155, 158, 161, 170, 172, 174, 174, 179, 188, 192, 184, 170, 174,\n",
              "        203,  85],\n",
              "       [  0,  98, 162, 148, 146, 140, 137, 146, 147, 152, 153, 155, 158,\n",
              "        164, 166, 169, 171, 172, 179, 175, 176, 180, 187, 180, 180, 183,\n",
              "        197,  92],\n",
              "       [ 49, 128, 133, 162, 175, 179, 178, 165, 162, 157, 158, 165, 178,\n",
              "        180, 180, 187, 190, 194, 202, 207, 210, 205, 216, 217, 212, 212,\n",
              "        216,  94],\n",
              "       [ 28, 131, 138, 140, 144, 161, 171, 184, 196, 194, 194, 197, 205,\n",
              "        208, 206, 202, 201, 201, 197, 194, 190, 180, 175, 165, 152, 147,\n",
              "        157, 112],\n",
              "       [  0,   0,  48, 116, 158, 164, 151, 157, 160, 169, 172, 172, 172,\n",
              "        183, 185, 202, 181, 171, 152, 170, 170, 162, 167, 175, 170, 162,\n",
              "        157, 123],\n",
              "       [  3,   0,   0,   0,   6,  53, 105, 143, 169, 165, 185, 183, 194,\n",
              "        172,  69,  38,  20,   1,   0,  67, 216, 213, 202, 210, 208, 198,\n",
              "        192, 134],\n",
              "       [  0,   2,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,\n",
              "          1,   0,   0,   0,   1,   0,   0,  47,  56,  48,  41,  43,  39,\n",
              "         35,   1],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke8WXI0vEpvM",
        "outputId": "6d7b18ef-3be2-45b4-c0d2-728e59bf588b"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S8JokCgEVBl",
        "outputId": "ad841f07-1a0e-4e97-8b0d-e65834176ba6"
      },
      "source": [
        "\n",
        "train_labels[50000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "i8fB_vCimGO4",
        "outputId": "b330f8c9-4a66-430c-8be3-b119d89875fb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[50000]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0HH3T-6E7lo"
      },
      "source": [
        "Estudiamos los **datos de prueba**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRBG6B5cE8O6",
        "outputId": "b643df63-0042-4850-8385-f59ac29c2f78"
      },
      "source": [
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJi4sf8bFE9A",
        "outputId": "d05110fc-4380-4351-bc51-08a1986b3ea3"
      },
      "source": [
        "test_images[5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   2,  96, 224, 120,  59,\n",
              "         59,  57,  63, 127, 216,  46,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 161, 233, 221, 215, 249, 249,\n",
              "        234, 233, 248, 242, 205, 231, 195,  63,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 176, 251, 222, 225, 204, 190, 201,\n",
              "        207, 208, 199, 194, 220, 227, 235, 245,  71,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  15, 233, 226, 226, 225, 239, 240, 227,\n",
              "        218, 209, 219, 239, 228, 225, 223, 241, 175,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  77, 249, 226, 230, 229, 228, 219, 164,\n",
              "        171, 246, 223, 222, 223, 230, 229, 234, 219,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 139, 246, 231, 217, 175, 138, 122, 135,\n",
              "        140, 250, 216, 225, 225, 227, 232, 231, 247,  54,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 203, 243, 238, 182, 140, 130,  92, 101,\n",
              "        211, 236, 228, 221, 222, 228, 233, 231, 253, 129,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 252, 237, 236, 255, 188, 130, 156, 196,\n",
              "        252, 235, 215, 244, 235, 233, 245, 235, 248, 198,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 216, 237, 236, 208, 255, 245, 254, 247,\n",
              "        213, 244, 158, 226, 234, 240, 234, 240, 244, 222,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 230, 238, 232, 116, 255, 228, 227, 232,\n",
              "        202,  96,  18,  96, 255, 220, 104, 251, 240, 212,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 227, 249, 187,  65, 255, 228, 229, 226,\n",
              "        255, 116,   0, 197, 225, 233,  53, 255, 239, 226,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  25, 227, 254, 152,   0, 255, 237, 249, 240,\n",
              "        232, 255, 249, 246, 255, 197,   0, 255, 239, 237,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  91, 245, 251,  83,   0, 255, 218, 142, 218,\n",
              "        247, 239, 246, 231, 247, 182,   0, 255, 241, 240,  23,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 109, 243, 252,  36,  36, 255, 199, 121, 182,\n",
              "        200, 198, 202, 234, 248, 248,   0, 255, 242, 247,  78,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 122, 242, 255,  21, 103, 255, 213, 163, 191,\n",
              "        152, 221, 109, 211, 242, 255,  27, 255, 246, 247,  76,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 156, 242, 255,  24, 174, 255, 241, 137, 164,\n",
              "        188, 171, 171, 255, 224, 255,  75, 205, 250, 251, 115,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 167, 243, 255,   1, 207, 251, 243, 202, 143,\n",
              "        125, 155, 250, 236, 225, 255,  89, 149, 255, 247, 136,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 178, 243, 255,  14, 234, 248, 230, 250, 244,\n",
              "        222, 254, 236, 234, 229, 255, 154, 130, 255, 243, 165,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 180, 246, 255,  43, 252, 231, 231, 226, 232,\n",
              "        239, 228, 230, 229, 225, 250, 206, 114, 255, 242, 182,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 179, 249, 238,  68, 255, 242, 242, 252, 251,\n",
              "        250, 252, 251, 251, 242, 255, 238, 106, 255, 240, 186,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 178, 250, 230,  43, 202, 181, 186, 189, 191,\n",
              "        192, 193, 192, 193, 190, 195, 169,  73, 255, 241, 185,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 173, 251, 215,  80, 230, 188, 191, 191, 192,\n",
              "        194, 195, 195, 195, 194, 216, 219,  89, 244, 242, 185,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 159, 250, 207,   5,  94,  88,  87,  91,  93,\n",
              "        101, 107, 105, 108, 110, 115,  83,  62, 251, 241, 173,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 148, 255, 214,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,  13, 248, 252, 173,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  93, 238, 189,   0,   0,   5,   4,   9,   9,\n",
              "         10,   5,   5,   5,   5,   7,   0,   0, 206, 219,  77,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  61, 190, 164,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   2,   0,   4, 196, 201,  60,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  44, 177, 147,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   1,   0,   0, 143, 168,  36,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5ieGjtRFNyw",
        "outputId": "283918f6-2e9b-443e-8fa5-2a5c0797c4c5"
      },
      "source": [
        "test_labels[5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl6a9LjNFQo-",
        "outputId": "339b094e-f14a-482b-e760-392fb1537192"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Fsnv_tgzFh3V",
        "outputId": "f51499d2-7444-46d1-9fd2-83f0e6bde3cf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = test_images[5000]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfv94Wr6jZMH"
      },
      "source": [
        "Construimos la **RNA** para casos del 1 al 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UWOX0bSlmYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddefd6af-dce8-4c03-d941-ae55ec90eb04"
      },
      "source": [
        "# 3.- CONSTRUIMOS LA ARQUITECTURA DE LA RED\n",
        "# 4.- HACEMOS EL PASO DE COMPILACIÓN  \n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "#MODELO 1 -> 10 / relu / sgd\n",
        "network1 = models.Sequential()\n",
        "network1.add(layers.Dense(10, activation='relu', input_shape=(28*28,), name = 'capa1'))\n",
        "network1.add(layers.Dense(10, activation='softmax', name = 'capa2'))\n",
        "\n",
        "network1.summary()\n",
        "# 7850 = 784 x 10 + 10 Sesgo\n",
        "# 110 = 10x10 + 10 Sesgo\n",
        "# 7960 = 7850 + 110\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "capa1 (Dense)                (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "capa2 (Dense)                (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLEfaIQtrZ9_"
      },
      "source": [
        "network1.compile(optimizer='sgd', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeM3b2jDLNG0"
      },
      "source": [
        "**MODELO 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGcnSW1vK4wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b632edf-8a7e-445d-970c-09572eb39453"
      },
      "source": [
        "#MODELO 2 -> 10 / relu / rmsprop\n",
        "network2 = models.Sequential()\n",
        "network2.add(layers.Dense(10, activation='relu', input_shape=(28*28,)))\n",
        "network2.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network2.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inOnBkrULC6O"
      },
      "source": [
        "network2.compile(optimizer='rmsprop', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7wJ4UJpLIm5"
      },
      "source": [
        "**MODELO 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTsmGkh9nJJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d001715b-3533-46dc-e3c0-97190a514a82"
      },
      "source": [
        "#MODELO 3 -> 10 / sigmoid / sgd\n",
        "network3 = models.Sequential()\n",
        "network3.add(layers.Dense(10, activation='sigmoid', input_shape=(28*28,)))\n",
        "network3.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network3.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zReE6pZWsDgu"
      },
      "source": [
        "network3.compile(optimizer='sgd', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg4Q2yzTLSNj"
      },
      "source": [
        "**MODELO 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UN1q8TeLRmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee00dda4-d64f-4c4c-8019-6a4360a86a7f"
      },
      "source": [
        "#MODELO 4 -> 10 / sigmoid / rmsprop\n",
        "network4 = models.Sequential()\n",
        "network4.add(layers.Dense(10, activation='sigmoid', input_shape=(28*28,)))\n",
        "network4.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network4.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtKu5FJRLfpD"
      },
      "source": [
        "network4.compile(optimizer='rmsprop', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTPfIw6tZCL3"
      },
      "source": [
        "TRANSFORMACIÓN DATOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGfryO7SZC7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b51ce7-b2ae-4d8f-9c7b-83b8d3dde5cd"
      },
      "source": [
        "# 5.- PREPARAMOS LOS DATOS DE IMAGEN CON ALGUNA TRANSFORMACIÓN. NORMALIZACION\n",
        "# Los tensores transformados tienen la misma cantidad de datos total que el \n",
        "# tensor inicial\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images, len(train_images), train_images.shape, train_images[50000]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   1,   0,   0,   0,   0,   2,   0,   1,   0,\n",
              "         16,  94,   0,   0,   2,   1,   1,   0,   1,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   1,   0,   1,   1,   0,   0,\n",
              "          1,   0, 101, 196, 187,   8,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,   1,\n",
              "          0,   1,   0,   0, 161, 167, 166, 112,  11,   1,   0,   0,   6,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "          0,   0,   0,   3,   0, 121, 213, 187, 183, 180, 179, 155, 147,\n",
              "        129, 175,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          1,   0,   0,   1,   2,   1,   0, 119, 198, 183, 185, 170, 185,\n",
              "        172, 170, 170, 146,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   2,   3,   0,   0, 175, 208, 176, 212,\n",
              "        180, 174, 166, 164, 164, 144,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,  73, 255, 192,\n",
              "        134, 175, 183, 192, 184, 189, 179, 193,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   2,   1,   0,   0,  70, 192,\n",
              "        170, 134, 189, 192, 175, 157, 156, 171, 149, 180,   8,   0,   0,\n",
              "          0,   1,   0,   0,   0,   0,   0,   1,   3,   1,   0,  35,  99,\n",
              "        181, 183, 126, 175, 197, 208, 203, 197, 188, 175, 158, 187,  14,\n",
              "          1,   1,   0,   0,   1,   1,   1,   1,   2,   2,   0,   0,  70,\n",
              "        188, 188, 116, 131, 180, 202, 190, 181, 188, 187, 175, 167, 156,\n",
              "        199,  34,   0,   0,   3,   3,   2,   0,   0,   0,   0,   0,   3,\n",
              "         69, 179, 106, 134, 151, 187, 183, 178, 171, 169, 187, 187, 183,\n",
              "        188, 167, 210,  53,   0,   0,   0,   0,   0,   0,   1,  11,  19,\n",
              "         57, 114, 130, 125, 129, 160, 174, 178, 184, 185, 196, 197, 198,\n",
              "        192, 188, 189, 166, 211,  52,   7,   0,  29,  87,  88, 105, 101,\n",
              "         99, 108, 110, 110, 137, 155, 166, 174, 179, 174, 176, 180, 181,\n",
              "        181, 180, 180, 184, 174, 169, 211,  66,   0,  19, 143, 119, 115,\n",
              "        116, 111, 114, 119, 116, 125, 139, 147, 155, 158, 161, 170, 172,\n",
              "        174, 174, 179, 188, 192, 184, 170, 174, 203,  85,   0,  98, 162,\n",
              "        148, 146, 140, 137, 146, 147, 152, 153, 155, 158, 164, 166, 169,\n",
              "        171, 172, 179, 175, 176, 180, 187, 180, 180, 183, 197,  92,  49,\n",
              "        128, 133, 162, 175, 179, 178, 165, 162, 157, 158, 165, 178, 180,\n",
              "        180, 187, 190, 194, 202, 207, 210, 205, 216, 217, 212, 212, 216,\n",
              "         94,  28, 131, 138, 140, 144, 161, 171, 184, 196, 194, 194, 197,\n",
              "        205, 208, 206, 202, 201, 201, 197, 194, 190, 180, 175, 165, 152,\n",
              "        147, 157, 112,   0,   0,  48, 116, 158, 164, 151, 157, 160, 169,\n",
              "        172, 172, 172, 183, 185, 202, 181, 171, 152, 170, 170, 162, 167,\n",
              "        175, 170, 162, 157, 123,   3,   0,   0,   0,   6,  53, 105, 143,\n",
              "        169, 165, 185, 183, 194, 172,  69,  38,  20,   1,   0,  67, 216,\n",
              "        213, 202, 210, 208, 198, 192, 134,   0,   2,   2,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   5,   1,   0,   0,   0,   1,   0,\n",
              "          0,  47,  56,  48,  41,  43,  39,  35,   1,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUd3O774Zi8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebbb02a-bb75-45f0-f2eb-046c94763329"
      },
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "train_images, len(train_images), train_images.shape, train_images[50000]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00784314, 0.        , 0.00392157, 0.        ,\n",
              "        0.0627451 , 0.36862746, 0.        , 0.        , 0.00784314,\n",
              "        0.00392157, 0.00392157, 0.        , 0.00392157, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.        , 0.00392157, 0.00392157, 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.39607844, 0.76862746,\n",
              "        0.73333335, 0.03137255, 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        , 0.00392157, 0.        ,\n",
              "        0.        , 0.6313726 , 0.654902  , 0.6509804 , 0.4392157 ,\n",
              "        0.04313726, 0.00392157, 0.        , 0.        , 0.02352941,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01176471, 0.        , 0.4745098 , 0.8352941 ,\n",
              "        0.73333335, 0.7176471 , 0.7058824 , 0.7019608 , 0.60784316,\n",
              "        0.5764706 , 0.5058824 , 0.6862745 , 0.03137255, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.00392157, 0.00784314, 0.00392157,\n",
              "        0.        , 0.46666667, 0.7764706 , 0.7176471 , 0.7254902 ,\n",
              "        0.6666667 , 0.7254902 , 0.6745098 , 0.6666667 , 0.6666667 ,\n",
              "        0.57254905, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00784314, 0.01176471, 0.        , 0.        , 0.6862745 ,\n",
              "        0.8156863 , 0.6901961 , 0.83137256, 0.7058824 , 0.68235296,\n",
              "        0.6509804 , 0.6431373 , 0.6431373 , 0.5647059 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
              "        0.        , 0.28627452, 1.        , 0.7529412 , 0.5254902 ,\n",
              "        0.6862745 , 0.7176471 , 0.7529412 , 0.72156864, 0.7411765 ,\n",
              "        0.7019608 , 0.75686276, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
              "        0.00392157, 0.        , 0.        , 0.27450982, 0.7529412 ,\n",
              "        0.6666667 , 0.5254902 , 0.7411765 , 0.7529412 , 0.6862745 ,\n",
              "        0.6156863 , 0.6117647 , 0.67058825, 0.58431375, 0.7058824 ,\n",
              "        0.03137255, 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.01176471, 0.00392157, 0.        , 0.13725491,\n",
              "        0.3882353 , 0.70980394, 0.7176471 , 0.49411765, 0.6862745 ,\n",
              "        0.77254903, 0.8156863 , 0.79607844, 0.77254903, 0.7372549 ,\n",
              "        0.6862745 , 0.61960787, 0.73333335, 0.05490196, 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00784314, 0.00784314, 0.        ,\n",
              "        0.        , 0.27450982, 0.7372549 , 0.7372549 , 0.45490196,\n",
              "        0.5137255 , 0.7058824 , 0.7921569 , 0.74509805, 0.70980394,\n",
              "        0.7372549 , 0.73333335, 0.6862745 , 0.654902  , 0.6117647 ,\n",
              "        0.78039217, 0.13333334, 0.        , 0.        , 0.01176471,\n",
              "        0.01176471, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.27058825, 0.7019608 ,\n",
              "        0.41568628, 0.5254902 , 0.5921569 , 0.73333335, 0.7176471 ,\n",
              "        0.69803923, 0.67058825, 0.6627451 , 0.73333335, 0.73333335,\n",
              "        0.7176471 , 0.7372549 , 0.654902  , 0.8235294 , 0.20784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.04313726, 0.07450981, 0.22352941,\n",
              "        0.44705883, 0.50980395, 0.49019608, 0.5058824 , 0.627451  ,\n",
              "        0.68235296, 0.69803923, 0.72156864, 0.7254902 , 0.76862746,\n",
              "        0.77254903, 0.7764706 , 0.7529412 , 0.7372549 , 0.7411765 ,\n",
              "        0.6509804 , 0.827451  , 0.20392157, 0.02745098, 0.        ,\n",
              "        0.11372549, 0.34117648, 0.34509805, 0.4117647 , 0.39607844,\n",
              "        0.3882353 , 0.42352942, 0.43137255, 0.43137255, 0.5372549 ,\n",
              "        0.60784316, 0.6509804 , 0.68235296, 0.7019608 , 0.68235296,\n",
              "        0.6901961 , 0.7058824 , 0.70980394, 0.70980394, 0.7058824 ,\n",
              "        0.7058824 , 0.72156864, 0.68235296, 0.6627451 , 0.827451  ,\n",
              "        0.25882354, 0.        , 0.07450981, 0.56078434, 0.46666667,\n",
              "        0.4509804 , 0.45490196, 0.43529412, 0.44705883, 0.46666667,\n",
              "        0.45490196, 0.49019608, 0.54509807, 0.5764706 , 0.60784316,\n",
              "        0.61960787, 0.6313726 , 0.6666667 , 0.6745098 , 0.68235296,\n",
              "        0.68235296, 0.7019608 , 0.7372549 , 0.7529412 , 0.72156864,\n",
              "        0.6666667 , 0.68235296, 0.79607844, 0.33333334, 0.        ,\n",
              "        0.38431373, 0.63529414, 0.5803922 , 0.57254905, 0.54901963,\n",
              "        0.5372549 , 0.57254905, 0.5764706 , 0.59607846, 0.6       ,\n",
              "        0.60784316, 0.61960787, 0.6431373 , 0.6509804 , 0.6627451 ,\n",
              "        0.67058825, 0.6745098 , 0.7019608 , 0.6862745 , 0.6901961 ,\n",
              "        0.7058824 , 0.73333335, 0.7058824 , 0.7058824 , 0.7176471 ,\n",
              "        0.77254903, 0.36078432, 0.19215687, 0.5019608 , 0.52156866,\n",
              "        0.63529414, 0.6862745 , 0.7019608 , 0.69803923, 0.64705884,\n",
              "        0.63529414, 0.6156863 , 0.61960787, 0.64705884, 0.69803923,\n",
              "        0.7058824 , 0.7058824 , 0.73333335, 0.74509805, 0.7607843 ,\n",
              "        0.7921569 , 0.8117647 , 0.8235294 , 0.8039216 , 0.84705883,\n",
              "        0.8509804 , 0.83137256, 0.83137256, 0.84705883, 0.36862746,\n",
              "        0.10980392, 0.5137255 , 0.5411765 , 0.54901963, 0.5647059 ,\n",
              "        0.6313726 , 0.67058825, 0.72156864, 0.76862746, 0.7607843 ,\n",
              "        0.7607843 , 0.77254903, 0.8039216 , 0.8156863 , 0.80784315,\n",
              "        0.7921569 , 0.7882353 , 0.7882353 , 0.77254903, 0.7607843 ,\n",
              "        0.74509805, 0.7058824 , 0.6862745 , 0.64705884, 0.59607846,\n",
              "        0.5764706 , 0.6156863 , 0.4392157 , 0.        , 0.        ,\n",
              "        0.1882353 , 0.45490196, 0.61960787, 0.6431373 , 0.5921569 ,\n",
              "        0.6156863 , 0.627451  , 0.6627451 , 0.6745098 , 0.6745098 ,\n",
              "        0.6745098 , 0.7176471 , 0.7254902 , 0.7921569 , 0.70980394,\n",
              "        0.67058825, 0.59607846, 0.6666667 , 0.6666667 , 0.63529414,\n",
              "        0.654902  , 0.6862745 , 0.6666667 , 0.63529414, 0.6156863 ,\n",
              "        0.48235294, 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.20784314, 0.4117647 , 0.56078434, 0.6627451 ,\n",
              "        0.64705884, 0.7254902 , 0.7176471 , 0.7607843 , 0.6745098 ,\n",
              "        0.27058825, 0.14901961, 0.07843138, 0.00392157, 0.        ,\n",
              "        0.2627451 , 0.84705883, 0.8352941 , 0.7921569 , 0.8235294 ,\n",
              "        0.8156863 , 0.7764706 , 0.7529412 , 0.5254902 , 0.        ,\n",
              "        0.00784314, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.18431373,\n",
              "        0.21960784, 0.1882353 , 0.16078432, 0.16862746, 0.15294118,\n",
              "        0.13725491, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KG9BOFLZnLk"
      },
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUX69CgzZskU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad43930-f31a-4326-c3f2-720c22f99427"
      },
      "source": [
        "# 6.- PREPARACIÓN LAS ETIQUETAS\n",
        "# from keras import utils\n",
        "# from keras.utils import to_categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_labels[50000] # Posición 0 a 9 donde solo la 9 tiene probabilidad 1 (boot)."
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QepOz3kqsj4b"
      },
      "source": [
        "Entrenamos las redes de neuronas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4TLE9XyZw5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "5ee34911-10f3-48a7-ec53-e28765777804"
      },
      "source": [
        "network1.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-39d56eabd64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [128,10] and labels shape [1280]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-42-39d56eabd64e>:1) ]] [Op:__inference_train_function_1269]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glafWhSCsU72",
        "outputId": "34dcd97a-a988-45bf-e58c-245d4dd0dc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "network2.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-48537b206e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [128,10] and labels shape [1280]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-43-48537b206e95>:1) ]] [Op:__inference_train_function_1772]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2HEa5TesXDb",
        "outputId": "5d056c82-cd12-45ea-a03b-6cf2a104ab18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "network3.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-457714d05cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [128,10] and labels shape [1280]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-44-457714d05cd7>:1) ]] [Op:__inference_train_function_2134]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPdr2LILsZQg",
        "outputId": "64ec72c8-fd2a-417e-a08d-19f934923c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "network4.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-dd75e249ae54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [128,10] and labels shape [1280]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-45-dd75e249ae54>:1) ]] [Op:__inference_train_function_2637]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzPnyVQEscl1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8UupVX7cyBc"
      },
      "source": [
        "# 8.- VERIFICAMOS NUESTRO MODELO YA ENTRENADO, CONTRA EL CONJUNTO DE PRUEBAS\n",
        "test_loss, test_acc = network1.evaluate(test_images, test_labels)\n",
        "# HEMOS UTILIZADO MENOS DE 20 LÍNEAS DE CÓDIGO..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utDVNIRWc7_m"
      },
      "source": [
        "print('test_acc:', test_acc)\n",
        "# test_acc: 0.9777"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvWwLKiqdRJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "81a324cc-6702-4d54-b97f-496a74cb4c9e"
      },
      "source": [
        "# Veamos el elemento 6 de test y pintémoslo con matplotlib\n",
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "import matplotlib.pyplot as plt\n",
        "digit = test_images[5]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}