{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM24fkk+QfiXHPGM3Jup4IG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anamunoz01/AA_PRACTICA1_GRUPO_3/blob/main/Practica1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjS0Rz20khEw",
        "outputId": "ed145169-3a15-4162-84e9-8d30fce26751"
      },
      "source": [
        "# 1._ IMPORTAMOS KERAS\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.keras.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n",
            "GPU Available: []\n",
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IvCzPOlkp0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2322bf89-4895-4f53-d53b-fb9c714e1ed6"
      },
      "source": [
        "# Importamos las im√°genes\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "#creamos vector con elementos\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opyZVSAIDJND"
      },
      "source": [
        "Estudiamos los **datos de entrenamiento**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbHjZJhUlZE9",
        "outputId": "bdc7e8d8-0910-4426-d139-1357017cddf7"
      },
      "source": [
        "print(train_images.shape)\n",
        "\n",
        "train_images[50000]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   2,   0,   1,   0,  16,  94,   0,   0,   2,   1,   1,   0,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,\n",
              "          1,   0,   0,   1,   0, 101, 196, 187,   8,   0,   0,   0,   1,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,\n",
              "          1,   0,   1,   0,   0, 161, 167, 166, 112,  11,   1,   0,   0,\n",
              "          6,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0,   3,   0, 121, 213, 187, 183, 180, 179, 155, 147, 129,\n",
              "        175,   8],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "          1,   2,   1,   0, 119, 198, 183, 185, 170, 185, 172, 170, 170,\n",
              "        146,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          2,   3,   0,   0, 175, 208, 176, 212, 180, 174, 166, 164, 164,\n",
              "        144,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          2,   0,   0,  73, 255, 192, 134, 175, 183, 192, 184, 189, 179,\n",
              "        193,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   1,\n",
              "          0,   0,  70, 192, 170, 134, 189, 192, 175, 157, 156, 171, 149,\n",
              "        180,   8],\n",
              "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   3,   1,   0,\n",
              "         35,  99, 181, 183, 126, 175, 197, 208, 203, 197, 188, 175, 158,\n",
              "        187,  14],\n",
              "       [  1,   1,   0,   0,   1,   1,   1,   1,   2,   2,   0,   0,  70,\n",
              "        188, 188, 116, 131, 180, 202, 190, 181, 188, 187, 175, 167, 156,\n",
              "        199,  34],\n",
              "       [  0,   0,   3,   3,   2,   0,   0,   0,   0,   0,   3,  69, 179,\n",
              "        106, 134, 151, 187, 183, 178, 171, 169, 187, 187, 183, 188, 167,\n",
              "        210,  53],\n",
              "       [  0,   0,   0,   0,   0,   0,   1,  11,  19,  57, 114, 130, 125,\n",
              "        129, 160, 174, 178, 184, 185, 196, 197, 198, 192, 188, 189, 166,\n",
              "        211,  52],\n",
              "       [  7,   0,  29,  87,  88, 105, 101,  99, 108, 110, 110, 137, 155,\n",
              "        166, 174, 179, 174, 176, 180, 181, 181, 180, 180, 184, 174, 169,\n",
              "        211,  66],\n",
              "       [  0,  19, 143, 119, 115, 116, 111, 114, 119, 116, 125, 139, 147,\n",
              "        155, 158, 161, 170, 172, 174, 174, 179, 188, 192, 184, 170, 174,\n",
              "        203,  85],\n",
              "       [  0,  98, 162, 148, 146, 140, 137, 146, 147, 152, 153, 155, 158,\n",
              "        164, 166, 169, 171, 172, 179, 175, 176, 180, 187, 180, 180, 183,\n",
              "        197,  92],\n",
              "       [ 49, 128, 133, 162, 175, 179, 178, 165, 162, 157, 158, 165, 178,\n",
              "        180, 180, 187, 190, 194, 202, 207, 210, 205, 216, 217, 212, 212,\n",
              "        216,  94],\n",
              "       [ 28, 131, 138, 140, 144, 161, 171, 184, 196, 194, 194, 197, 205,\n",
              "        208, 206, 202, 201, 201, 197, 194, 190, 180, 175, 165, 152, 147,\n",
              "        157, 112],\n",
              "       [  0,   0,  48, 116, 158, 164, 151, 157, 160, 169, 172, 172, 172,\n",
              "        183, 185, 202, 181, 171, 152, 170, 170, 162, 167, 175, 170, 162,\n",
              "        157, 123],\n",
              "       [  3,   0,   0,   0,   6,  53, 105, 143, 169, 165, 185, 183, 194,\n",
              "        172,  69,  38,  20,   1,   0,  67, 216, 213, 202, 210, 208, 198,\n",
              "        192, 134],\n",
              "       [  0,   2,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,\n",
              "          1,   0,   0,   0,   1,   0,   0,  47,  56,  48,  41,  43,  39,\n",
              "         35,   1],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke8WXI0vEpvM",
        "outputId": "66b08ad1-a3df-4ac2-8c64-6845aa301acd"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S8JokCgEVBl",
        "outputId": "35220c8b-a166-4294-b30b-48dfd2191ed9"
      },
      "source": [
        "\n",
        "train_labels[50000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "i8fB_vCimGO4",
        "outputId": "fb64ec0b-6ee3-427c-824c-aa85f9722810"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[50000]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0HH3T-6E7lo"
      },
      "source": [
        "estudiamos los **datos de prueba**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRBG6B5cE8O6",
        "outputId": "abf42cea-2736-40d2-929e-037d10ebc8bb"
      },
      "source": [
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJi4sf8bFE9A",
        "outputId": "893ba345-2eb0-48f1-e38a-8142ba41bd28"
      },
      "source": [
        "test_images[5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   2,  96, 224, 120,  59,\n",
              "         59,  57,  63, 127, 216,  46,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 161, 233, 221, 215, 249, 249,\n",
              "        234, 233, 248, 242, 205, 231, 195,  63,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 176, 251, 222, 225, 204, 190, 201,\n",
              "        207, 208, 199, 194, 220, 227, 235, 245,  71,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  15, 233, 226, 226, 225, 239, 240, 227,\n",
              "        218, 209, 219, 239, 228, 225, 223, 241, 175,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,  77, 249, 226, 230, 229, 228, 219, 164,\n",
              "        171, 246, 223, 222, 223, 230, 229, 234, 219,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 139, 246, 231, 217, 175, 138, 122, 135,\n",
              "        140, 250, 216, 225, 225, 227, 232, 231, 247,  54,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 203, 243, 238, 182, 140, 130,  92, 101,\n",
              "        211, 236, 228, 221, 222, 228, 233, 231, 253, 129,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 252, 237, 236, 255, 188, 130, 156, 196,\n",
              "        252, 235, 215, 244, 235, 233, 245, 235, 248, 198,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 216, 237, 236, 208, 255, 245, 254, 247,\n",
              "        213, 244, 158, 226, 234, 240, 234, 240, 244, 222,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 230, 238, 232, 116, 255, 228, 227, 232,\n",
              "        202,  96,  18,  96, 255, 220, 104, 251, 240, 212,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0, 227, 249, 187,  65, 255, 228, 229, 226,\n",
              "        255, 116,   0, 197, 225, 233,  53, 255, 239, 226,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  25, 227, 254, 152,   0, 255, 237, 249, 240,\n",
              "        232, 255, 249, 246, 255, 197,   0, 255, 239, 237,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  91, 245, 251,  83,   0, 255, 218, 142, 218,\n",
              "        247, 239, 246, 231, 247, 182,   0, 255, 241, 240,  23,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 109, 243, 252,  36,  36, 255, 199, 121, 182,\n",
              "        200, 198, 202, 234, 248, 248,   0, 255, 242, 247,  78,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 122, 242, 255,  21, 103, 255, 213, 163, 191,\n",
              "        152, 221, 109, 211, 242, 255,  27, 255, 246, 247,  76,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 156, 242, 255,  24, 174, 255, 241, 137, 164,\n",
              "        188, 171, 171, 255, 224, 255,  75, 205, 250, 251, 115,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 167, 243, 255,   1, 207, 251, 243, 202, 143,\n",
              "        125, 155, 250, 236, 225, 255,  89, 149, 255, 247, 136,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 178, 243, 255,  14, 234, 248, 230, 250, 244,\n",
              "        222, 254, 236, 234, 229, 255, 154, 130, 255, 243, 165,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 180, 246, 255,  43, 252, 231, 231, 226, 232,\n",
              "        239, 228, 230, 229, 225, 250, 206, 114, 255, 242, 182,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 179, 249, 238,  68, 255, 242, 242, 252, 251,\n",
              "        250, 252, 251, 251, 242, 255, 238, 106, 255, 240, 186,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 178, 250, 230,  43, 202, 181, 186, 189, 191,\n",
              "        192, 193, 192, 193, 190, 195, 169,  73, 255, 241, 185,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 173, 251, 215,  80, 230, 188, 191, 191, 192,\n",
              "        194, 195, 195, 195, 194, 216, 219,  89, 244, 242, 185,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 159, 250, 207,   5,  94,  88,  87,  91,  93,\n",
              "        101, 107, 105, 108, 110, 115,  83,  62, 251, 241, 173,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 148, 255, 214,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,  13, 248, 252, 173,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  93, 238, 189,   0,   0,   5,   4,   9,   9,\n",
              "         10,   5,   5,   5,   5,   7,   0,   0, 206, 219,  77,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  61, 190, 164,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   2,   0,   4, 196, 201,  60,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  44, 177, 147,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   1,   0,   0, 143, 168,  36,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5ieGjtRFNyw",
        "outputId": "01b251af-3d13-4eac-e60b-682cc660d591"
      },
      "source": [
        "test_labels[5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl6a9LjNFQo-",
        "outputId": "61e07f45-f2ed-4d73-a3c7-eaf2fb501dc7"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Fsnv_tgzFh3V",
        "outputId": "842b1918-555c-43a1-fdb0-163563fb0691"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = test_images[5000]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfv94Wr6jZMH"
      },
      "source": [
        "Construimos la **RNA** para casos del 1 al 4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UWOX0bSlmYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4797e925-c856-4a39-e8e9-393765e9ad0e"
      },
      "source": [
        "# 3.- CONSTRUIMOS LA ARQUITECTURA DE LA RED\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "#MODELO 1 -> 10/ relu / sgd\n",
        "network1 = models.Sequential()\n",
        "network1.add(layers.Dense(10, activation='relu', input_shape=(28*28,), name = 'capa1'))\n",
        "network1.add(layers.Dense(10, activation='softmax', name = 'capa2'))\n",
        "\n",
        "network1.summary()\n",
        "# \n",
        "# 7850 = 784 x 10 + 10 Sesgo\n",
        "# 110 = 10x10 + 10 Sesgo\n",
        "# 7960 = 7850 + 110\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "capa1 (Dense)                (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "capa2 (Dense)                (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLEfaIQtrZ9_"
      },
      "source": [
        "# 4.- HACEMOS EL PASO DE COMPILACI√ìN  \n",
        "\n",
        "network1.compile(optimizer='sgd', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeM3b2jDLNG0"
      },
      "source": [
        "**MODELO 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGcnSW1vK4wH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96725a90-d0ce-4db0-feed-b7cc10ebc49f"
      },
      "source": [
        "#MODELO 2 -> 10/ relu\n",
        "network2 = models.Sequential()\n",
        "network2.add(layers.Dense(10, activation='relu', input_shape=(28*28,)))\n",
        "network2.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inOnBkrULC6O"
      },
      "source": [
        "network2.compile(optimizer='rmsprop', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7wJ4UJpLIm5"
      },
      "source": [
        "**MODELO 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTsmGkh9nJJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca2e770-b9e9-455b-d8f4-a5f5d1ba33fd"
      },
      "source": [
        "#MODELO 3 -> 10/ sgd\n",
        "network3 = models.Sequential()\n",
        "network3.add(layers.Dense(10, activation='sigmoid', input_shape=(28*28,)))\n",
        "network3.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zReE6pZWsDgu"
      },
      "source": [
        "network3.compile(optimizer='sgd', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg4Q2yzTLSNj"
      },
      "source": [
        "**MODELO 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UN1q8TeLRmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd40dc90-842d-48c2-8d77-b8b806bf3dae"
      },
      "source": [
        "network4 = models.Sequential()\n",
        "network4.add(layers.Dense(10, activation='sigmoid', input_shape=(28*28,)))\n",
        "network4.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtKu5FJRLfpD"
      },
      "source": [
        "network4.compile(optimizer='rmsprop', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTPfIw6tZCL3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGfryO7SZC7t",
        "outputId": "cb41acb7-3cee-4909-c296-7456502be280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 5.- PREPARAMOS LOS DATOS DE IMAGEN CON ALGUNA TRANSFORMACI√ìN. NORMALIZACION\n",
        "# Los tensores transformados tienen la misma cantidad de datos total que el \n",
        "# tensor inicial\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images, len(train_images), train_images.shape, train_images[50000]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   1,   0,   0,   0,   0,   2,   0,   1,   0,\n",
              "         16,  94,   0,   0,   2,   1,   1,   0,   1,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   1,   0,   1,   1,   0,   0,\n",
              "          1,   0, 101, 196, 187,   8,   0,   0,   0,   1,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,   1,\n",
              "          0,   1,   0,   0, 161, 167, 166, 112,  11,   1,   0,   0,   6,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "          0,   0,   0,   3,   0, 121, 213, 187, 183, 180, 179, 155, 147,\n",
              "        129, 175,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          1,   0,   0,   1,   2,   1,   0, 119, 198, 183, 185, 170, 185,\n",
              "        172, 170, 170, 146,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   2,   3,   0,   0, 175, 208, 176, 212,\n",
              "        180, 174, 166, 164, 164, 144,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,  73, 255, 192,\n",
              "        134, 175, 183, 192, 184, 189, 179, 193,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   2,   1,   0,   0,  70, 192,\n",
              "        170, 134, 189, 192, 175, 157, 156, 171, 149, 180,   8,   0,   0,\n",
              "          0,   1,   0,   0,   0,   0,   0,   1,   3,   1,   0,  35,  99,\n",
              "        181, 183, 126, 175, 197, 208, 203, 197, 188, 175, 158, 187,  14,\n",
              "          1,   1,   0,   0,   1,   1,   1,   1,   2,   2,   0,   0,  70,\n",
              "        188, 188, 116, 131, 180, 202, 190, 181, 188, 187, 175, 167, 156,\n",
              "        199,  34,   0,   0,   3,   3,   2,   0,   0,   0,   0,   0,   3,\n",
              "         69, 179, 106, 134, 151, 187, 183, 178, 171, 169, 187, 187, 183,\n",
              "        188, 167, 210,  53,   0,   0,   0,   0,   0,   0,   1,  11,  19,\n",
              "         57, 114, 130, 125, 129, 160, 174, 178, 184, 185, 196, 197, 198,\n",
              "        192, 188, 189, 166, 211,  52,   7,   0,  29,  87,  88, 105, 101,\n",
              "         99, 108, 110, 110, 137, 155, 166, 174, 179, 174, 176, 180, 181,\n",
              "        181, 180, 180, 184, 174, 169, 211,  66,   0,  19, 143, 119, 115,\n",
              "        116, 111, 114, 119, 116, 125, 139, 147, 155, 158, 161, 170, 172,\n",
              "        174, 174, 179, 188, 192, 184, 170, 174, 203,  85,   0,  98, 162,\n",
              "        148, 146, 140, 137, 146, 147, 152, 153, 155, 158, 164, 166, 169,\n",
              "        171, 172, 179, 175, 176, 180, 187, 180, 180, 183, 197,  92,  49,\n",
              "        128, 133, 162, 175, 179, 178, 165, 162, 157, 158, 165, 178, 180,\n",
              "        180, 187, 190, 194, 202, 207, 210, 205, 216, 217, 212, 212, 216,\n",
              "         94,  28, 131, 138, 140, 144, 161, 171, 184, 196, 194, 194, 197,\n",
              "        205, 208, 206, 202, 201, 201, 197, 194, 190, 180, 175, 165, 152,\n",
              "        147, 157, 112,   0,   0,  48, 116, 158, 164, 151, 157, 160, 169,\n",
              "        172, 172, 172, 183, 185, 202, 181, 171, 152, 170, 170, 162, 167,\n",
              "        175, 170, 162, 157, 123,   3,   0,   0,   0,   6,  53, 105, 143,\n",
              "        169, 165, 185, 183, 194, 172,  69,  38,  20,   1,   0,  67, 216,\n",
              "        213, 202, 210, 208, 198, 192, 134,   0,   2,   2,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   5,   1,   0,   0,   0,   1,   0,\n",
              "          0,  47,  56,  48,  41,  43,  39,  35,   1,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUd3O774Zi8j",
        "outputId": "92945fc4-f596-4b64-d24b-e450427dde31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "train_images, len(train_images), train_images.shape, train_images[50000]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00784314, 0.        , 0.00392157, 0.        ,\n",
              "        0.0627451 , 0.36862746, 0.        , 0.        , 0.00784314,\n",
              "        0.00392157, 0.00392157, 0.        , 0.00392157, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.        , 0.00392157, 0.00392157, 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.39607844, 0.76862746,\n",
              "        0.73333335, 0.03137255, 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        , 0.00392157, 0.        ,\n",
              "        0.        , 0.6313726 , 0.654902  , 0.6509804 , 0.4392157 ,\n",
              "        0.04313726, 0.00392157, 0.        , 0.        , 0.02352941,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01176471, 0.        , 0.4745098 , 0.8352941 ,\n",
              "        0.73333335, 0.7176471 , 0.7058824 , 0.7019608 , 0.60784316,\n",
              "        0.5764706 , 0.5058824 , 0.6862745 , 0.03137255, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.00392157, 0.00784314, 0.00392157,\n",
              "        0.        , 0.46666667, 0.7764706 , 0.7176471 , 0.7254902 ,\n",
              "        0.6666667 , 0.7254902 , 0.6745098 , 0.6666667 , 0.6666667 ,\n",
              "        0.57254905, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00784314, 0.01176471, 0.        , 0.        , 0.6862745 ,\n",
              "        0.8156863 , 0.6901961 , 0.83137256, 0.7058824 , 0.68235296,\n",
              "        0.6509804 , 0.6431373 , 0.6431373 , 0.5647059 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
              "        0.        , 0.28627452, 1.        , 0.7529412 , 0.5254902 ,\n",
              "        0.6862745 , 0.7176471 , 0.7529412 , 0.72156864, 0.7411765 ,\n",
              "        0.7019608 , 0.75686276, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
              "        0.00392157, 0.        , 0.        , 0.27450982, 0.7529412 ,\n",
              "        0.6666667 , 0.5254902 , 0.7411765 , 0.7529412 , 0.6862745 ,\n",
              "        0.6156863 , 0.6117647 , 0.67058825, 0.58431375, 0.7058824 ,\n",
              "        0.03137255, 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.01176471, 0.00392157, 0.        , 0.13725491,\n",
              "        0.3882353 , 0.70980394, 0.7176471 , 0.49411765, 0.6862745 ,\n",
              "        0.77254903, 0.8156863 , 0.79607844, 0.77254903, 0.7372549 ,\n",
              "        0.6862745 , 0.61960787, 0.73333335, 0.05490196, 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00784314, 0.00784314, 0.        ,\n",
              "        0.        , 0.27450982, 0.7372549 , 0.7372549 , 0.45490196,\n",
              "        0.5137255 , 0.7058824 , 0.7921569 , 0.74509805, 0.70980394,\n",
              "        0.7372549 , 0.73333335, 0.6862745 , 0.654902  , 0.6117647 ,\n",
              "        0.78039217, 0.13333334, 0.        , 0.        , 0.01176471,\n",
              "        0.01176471, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.27058825, 0.7019608 ,\n",
              "        0.41568628, 0.5254902 , 0.5921569 , 0.73333335, 0.7176471 ,\n",
              "        0.69803923, 0.67058825, 0.6627451 , 0.73333335, 0.73333335,\n",
              "        0.7176471 , 0.7372549 , 0.654902  , 0.8235294 , 0.20784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.04313726, 0.07450981, 0.22352941,\n",
              "        0.44705883, 0.50980395, 0.49019608, 0.5058824 , 0.627451  ,\n",
              "        0.68235296, 0.69803923, 0.72156864, 0.7254902 , 0.76862746,\n",
              "        0.77254903, 0.7764706 , 0.7529412 , 0.7372549 , 0.7411765 ,\n",
              "        0.6509804 , 0.827451  , 0.20392157, 0.02745098, 0.        ,\n",
              "        0.11372549, 0.34117648, 0.34509805, 0.4117647 , 0.39607844,\n",
              "        0.3882353 , 0.42352942, 0.43137255, 0.43137255, 0.5372549 ,\n",
              "        0.60784316, 0.6509804 , 0.68235296, 0.7019608 , 0.68235296,\n",
              "        0.6901961 , 0.7058824 , 0.70980394, 0.70980394, 0.7058824 ,\n",
              "        0.7058824 , 0.72156864, 0.68235296, 0.6627451 , 0.827451  ,\n",
              "        0.25882354, 0.        , 0.07450981, 0.56078434, 0.46666667,\n",
              "        0.4509804 , 0.45490196, 0.43529412, 0.44705883, 0.46666667,\n",
              "        0.45490196, 0.49019608, 0.54509807, 0.5764706 , 0.60784316,\n",
              "        0.61960787, 0.6313726 , 0.6666667 , 0.6745098 , 0.68235296,\n",
              "        0.68235296, 0.7019608 , 0.7372549 , 0.7529412 , 0.72156864,\n",
              "        0.6666667 , 0.68235296, 0.79607844, 0.33333334, 0.        ,\n",
              "        0.38431373, 0.63529414, 0.5803922 , 0.57254905, 0.54901963,\n",
              "        0.5372549 , 0.57254905, 0.5764706 , 0.59607846, 0.6       ,\n",
              "        0.60784316, 0.61960787, 0.6431373 , 0.6509804 , 0.6627451 ,\n",
              "        0.67058825, 0.6745098 , 0.7019608 , 0.6862745 , 0.6901961 ,\n",
              "        0.7058824 , 0.73333335, 0.7058824 , 0.7058824 , 0.7176471 ,\n",
              "        0.77254903, 0.36078432, 0.19215687, 0.5019608 , 0.52156866,\n",
              "        0.63529414, 0.6862745 , 0.7019608 , 0.69803923, 0.64705884,\n",
              "        0.63529414, 0.6156863 , 0.61960787, 0.64705884, 0.69803923,\n",
              "        0.7058824 , 0.7058824 , 0.73333335, 0.74509805, 0.7607843 ,\n",
              "        0.7921569 , 0.8117647 , 0.8235294 , 0.8039216 , 0.84705883,\n",
              "        0.8509804 , 0.83137256, 0.83137256, 0.84705883, 0.36862746,\n",
              "        0.10980392, 0.5137255 , 0.5411765 , 0.54901963, 0.5647059 ,\n",
              "        0.6313726 , 0.67058825, 0.72156864, 0.76862746, 0.7607843 ,\n",
              "        0.7607843 , 0.77254903, 0.8039216 , 0.8156863 , 0.80784315,\n",
              "        0.7921569 , 0.7882353 , 0.7882353 , 0.77254903, 0.7607843 ,\n",
              "        0.74509805, 0.7058824 , 0.6862745 , 0.64705884, 0.59607846,\n",
              "        0.5764706 , 0.6156863 , 0.4392157 , 0.        , 0.        ,\n",
              "        0.1882353 , 0.45490196, 0.61960787, 0.6431373 , 0.5921569 ,\n",
              "        0.6156863 , 0.627451  , 0.6627451 , 0.6745098 , 0.6745098 ,\n",
              "        0.6745098 , 0.7176471 , 0.7254902 , 0.7921569 , 0.70980394,\n",
              "        0.67058825, 0.59607846, 0.6666667 , 0.6666667 , 0.63529414,\n",
              "        0.654902  , 0.6862745 , 0.6666667 , 0.63529414, 0.6156863 ,\n",
              "        0.48235294, 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.20784314, 0.4117647 , 0.56078434, 0.6627451 ,\n",
              "        0.64705884, 0.7254902 , 0.7176471 , 0.7607843 , 0.6745098 ,\n",
              "        0.27058825, 0.14901961, 0.07843138, 0.00392157, 0.        ,\n",
              "        0.2627451 , 0.84705883, 0.8352941 , 0.7921569 , 0.8235294 ,\n",
              "        0.8156863 , 0.7764706 , 0.7529412 , 0.5254902 , 0.        ,\n",
              "        0.00784314, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.18431373,\n",
              "        0.21960784, 0.1882353 , 0.16078432, 0.16862746, 0.15294118,\n",
              "        0.13725491, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KG9BOFLZnLk"
      },
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUX69CgzZskU",
        "outputId": "089700b1-79d9-40fd-ea8d-c5ebb2eeb73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 6.- PREPARACI√ìN LAS ETIQUETAS\n",
        "# from keras import utils\n",
        "# from keras.utils import to_categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_labels[50000] # Posici√≥n 0 a 9 donde solo la 9 tiene probabilidad 1."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4TLE9XyZw5_",
        "outputId": "5569ebc1-f6be-4f1c-dd17-4bfa595d1ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "network1.fit(train_images, train_labels, epochs=5, batch_size= 128)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cb3aa030bc50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2791\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    }
  ]
}